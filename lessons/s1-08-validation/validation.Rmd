---
title: Data validation
author: LPO 9951 | Fall 2016
output: github_document
---

```{r, echo = FALSE, message = FALSE}
require(knitr)
source('../../r/stataknitrhelper.r')
opts_chunk$set(echo = FALSE, message = FALSE, comment = NA)
```

```{r, engine = 'bash'}
## run accompanying .do file to get log file for parsing
#stata -b -q do ../do/lecture10_validation.do
```

```{r}
## save log file in object
lf <- 'lecture10_validation.log'
```
Data validation refers to the process of ensuring that the
characteristics of your data match the known characteristics of the
population as measured by other analysts. If you have large
discrepancies between your estimates and the estimates compiled by
others, this is a clear "red flag" that something has gone
wrong. Usually this is a problem that can be solved by going back to
cleaning the data, but sometimes your sample may diverge in important
ways from the samples collected by others. You will need to state
why this is the case in your write-up of the data.

Data validation can be done in several ways:

  * You can compare the estimates from your dataset with the estimates
  from another analysis of the same dataset. This is what we will do
  with the datasets used in this class.
  * Sometimes you will be the first one to analyze your dataset. In
  this case, you need to look for others who have collected similar
  samples and compare with them.
  * Sometimes you won't have any other samples to work with. In this
  case, you'll need to see if there are population data that might be
  useful. Many people use the Census as a "check" on the data they
  have collected.
  * Last, you need to use common sense. If you have data on private
    elite institutions of higher education, and you calculate an
    average tuition of $2,000, you can rest assured that you have not
    found a hidden bargain but rather a flaw in your data.

## Adding new subdirectory: `./tables/`

First things first, you need to add a new subdirectory `./tables/` to
your class folder. It should be of the same level as the other
subdirectories you've already created: `data`, `do`, `plots`, `aux`.

<br>

## Calculating estimates and comparing them with known results

Today, we'll use the `plans` dataset. We're going to compare our
results with several tables published by NCES. Let's start with
educational expectations of high school sophomores. We start by survey
setting the data:  

```{r}
start <- 'load plans data'
end <- 'set up local to hold variables we wish to recode'
writeLines(logparse(lf, start = start, end = end))
```
<br>

### Account for missing data
The next step is to account for missing data properly:

```{r}
start <- 'set up local to hold variables we wish to recode'
end <- 'student expectations for education'
writeLines(logparse(lf, start = start, end = end))
```

<br>

### Get estimates

Next, we tabulate expectations for college and compare it to a known
estimate. 

```{r}
start <- 'student expectations for education'
end <- 'store estimates'
writeLines(logparse(lf, start = start, end = end))
```
<br>

### Nicer tables

We get output in the console, but let's use the `eststo` and
`esttab` commands to store our estimates and produce nicer
tables. Using `esttab` alone, we'll get a nicely formatted table in
the console. By adding `... using <file>` we save an `.rtf` version of
the same table. We can easily paste this table in a paper. If you are
feeling bold, you could output the table in LaTeX format and
incorporate into your LaTeX-formatted document.  

```{r}
start <- 'store estimates'
end <- 'end file' 
writeLines(logparse(lf, start = start, end = end))
```

*NB:* The `///` at the end of each line in the `esttab` commands tells
Stata to move to the next line but that the command isn't yet
finished. Without this, the options would stretch far on one line: bad
coding practice. I could have also changed the delimiter to `;` like
we did when reading in NCES datasets in the earlier lecture.

<br>

### Validate with published data

Now that we have a clean table to look at, is this the same as
[Table 2 on page 22 of the report](http://nces.ed.gov/pubs2005/2005338.pdf#50)?
Yes. Checking the standard errors reveals that there were also
correctly done. Now we need to check this for all of the other
variables in our dataset.  

<br>

#### Not-so-quick Exercise
> I want you to replicate
> [Table 34 on page 128 of NCES 2005-338](http://nces.ed.gov/pubs2005/2005338.pdf#154). We'll
> split this up, but I want the class to come up with a single table
> that has exactly the same results as the NCES document. 

<br><br>

*Init: 25 August 2015; Updated: `r format(Sys.Date(), format = "%d %B %Y")`*

<br>
