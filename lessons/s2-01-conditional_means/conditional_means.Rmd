---
title: Regression and Conditional Means
author: LPO 9952 | Spring 2017
output: github_document
---

```{r, echo = FALSE, message = FALSE}
require(knitr)
source('../../r/stataknitrhelper.r')
opts_chunk$set(echo = FALSE, message = FALSE, comment = NA)
```

```{r, engine = 'bash'}
## run accompanying .do file to get log file for parsing
#stata -b -q do ../do/lecture11_descriptives.do
## convert plots used in this file to png
#pdir=/
glist=(uncond_mean
cond_mean2
cond_mean4
cond_mean10
regress
)

for i in ${glist[@]};
do
convert -density 150 -flatten $pdir$i.eps $pdir$i.png;
done
```

```{r}
## save log file in object
lf <- 'cond_mean.log'
```

## Unconditional Means as a Prediction

In most of our day-to-day thinking, we use unconditional means as the basis for making pre- dictions. For instance, if I asked you to predict the temperature on June 1st of this year, you’d most likely simply say it would be the average temperature for that day or that time of year.

In the example below, I calculate the mean of math test scores in the plans dataset and use it as a prediction. I calculate the error term, then calculate the mean squared error (which is exactly what it sounds like) as a measure of how good this prediction is. As the graphic shows, the mean is a pretty terrible predictor for most people.

```{r}
start <- 'Using the mean as a prediction'
end <- 'Above average vs. below average'
writeLines(logparse(lf, start = start,end=end))
```


```{r, results = 'asis'}
writeLines(alignfigure('uncond_mean.png', 'center'))
```

*Quick Exercise* Calculate the mean of reading scores by ses, then make a prediction and calculate the mean squared error. Plot the result.

## Predictions Using Conditional Means: 2 Groups

With condtional means, we start using more information to think about how we will make our prediction. One of the simplest ways to do this in a bivariate sense is to calculate the mean of the dependent variable for individuals who are above average and below average.

Here’s a plot of the condtional mean of math scores by SES, for above average and below average SES.

```{r}
start <- 'Above average vs. below average'
end <- 'Conditional mean by Quartiles*'
writeLines(logparse(lf, start = start,end=end))
```

```{r, results = 'asis'}
writeLines(alignfigure('cond_mean2.png', 'center'))
```


*Quick Exercise* Calculate the mean of reading scores by 2 levels of ses, then make predictions and calculate the mean squared error. Plot the result.

## Predictions Using Conditional Means: 4 Groups

We can continue with this logic through any number of arbitrary subdivsitons. Here’s a plot of the conditional mean of math scores by SES by quartile.


```{r}
start <- 'Conditional mean by Quartiles*'
end <- 'Conditional means across Deciles'
writeLines(logparse(lf, start = start,end=end))
```



```{r, results = 'asis'}
writeLines(alignfigure('cond_mean4.png', 'center'))
```


*Quick Exercise* Calculate the mean of reading scores by 4 levels of ses, then make predictions and calculate the mean squared error. Plot the result.

## Predictions Using Conditional Means: 10 Groups

This logic can be extended indefinitely. For instance, here's a plot of the conditional mean of math scores at 10 different levels of SES.

```{r}
start <- 'Conditional means across Deciles'
end <- 'Conditional Mean: Regression'

writeLines(logparse(lf, start = start,end=end))
```



*Quick Exercise* Calculate the mean of reading scores by 20 levels of ses, then make predictions and calculate the mean squared error. Plot the result.


## Regression is the conditional mean for ALL X's

Regression is based on the idea of the expected value of y given, E(Y |X). If X can take on only two values, then regression will give two predictions. If X can take on 4, then it will give that many, based on the existing data. What regression does is calculate an expected value of Y at every level of X. The constraint is that the fit must be linear: it can only summarize the data using a straight line, set by two parameters (intercept and slope). How it does this is the subject of your regression class this semester. 

Below, I regress math scores on SES, then predict math scores at every observed level of SES. I then plot this prediction. 

```{r}
start <- 'Conditional Mean: Regression'
end <- NULL

writeLines(logparse(lf, start = start,end=end))
```

```{r, results = 'asis'}
writeLines(alignfigure('regress.png', 'center'))
```

*Quick Exercise* Use regression to predict reading scores. Compare the mse from your regression to the mse from the other methods used. What do you observe? 
